{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous notebook](./sgd.ipynb), we saw how useful the automatic gradient computation provided by tensorflow can be. Now, we get to know further pieces of tensorflow code that help us in reducing boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous notebook](./mlp.ipynb), we explicitly defined the neural network in terms of matrix multiplications and activation functions. In particular, when we go to deeper models later proceeding in this way could become very tedious. Using the ``tensorflow`` library `Keras`, we can remove much of this boilerplate code, so that building deep networks becomes playing lego!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras` is built on top of the concept of `Layer`s that can be combined in a flexible way. For us a layer is essentially a matrix multiplication together with a non-linearity. Later in the course, we will meet more refined examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = 5\n",
    "\n",
    "x = tf.keras.layers.Input(shape = (input_dim,))\n",
    "y = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(x,y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we generate simple training data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "input_size = int(1e6)\n",
    "\n",
    "w_true = tf.transpose([[1., 2., 3., 4., 5.]])\n",
    "x = tf.random_uniform((input_size, input_dim), -1, 1)\n",
    "y = tf.matmul(x,w_true) + tf.random_uniform((input_size,1), -.1, .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we `compile` the model by specifying the loss function and the optimizer. We go for mean-squared error and plain SGD. After that we fit the model to the data. The parameter `epochs` determines how many passes we make over the data. `batch_size` controls the size of the mini-batch for the stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000000/1000000 [==============================] - 124s 124us/step - loss: 0.1737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fa7db928898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "model.compile(loss='mse', optimizer=tf.train.GradientDescentOptimizer(learning_rate = .01))\n",
    "model.fit(x, y, epochs = 1, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether we have achieved convergence to the correct parameters, we peek inside the weight matrix. First, there are two layers: one formal input layer, and the actual dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras._impl.keras.engine.input_layer.InputLayer at 0x7fa7dc197ac8>,\n",
       " <tensorflow.python.keras._impl.keras.layers.core.Dense at 0x7fa7dc197b38>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dense layer, we can now extract the weights and thereby verify the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(5, 1) dtype=float32, numpy=\n",
       " array([[0.9998297],\n",
       "        [1.9995269],\n",
       "        [2.9989161],\n",
       "        [4.0008774],\n",
       "        [5.000411 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.00014079], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train a Keras MLP for the Iris dataset. What is a suitable loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
