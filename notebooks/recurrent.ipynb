{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the [exception of RBMs](./rbm.ipynb), we have so far mainly witnessed the power of deep nets in the context of [supervised learning](./sgd.ipynb). In other words, given a certain amount of data, we used deep nets to predict the price of a house or the type of a flower. In the present notebook, we see that deep nets can also generate data -- such as Nietzsche literature! The analysis of language using AI is also known as **natural language processing (NLP)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, before diving into the generation task, we need to talk about new architecture for dealing with sequence data: **recurrent neural networks (RNNs)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to represent text as data, we have several options such as encoding single characters or words, or even groups of words - called *n-grams*. However, none of these representations is nicely compatible with MLPs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, first MLPs expect a fixed-length input, whereas sentences can arguably be of very different length, as the following quotes illustrate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barack Obama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Yes, we can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immanuel Kant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ist\n",
    "dieses nun nicht geschehen, und kann es auch, wegen der Untauglichkeit\n",
    "des gemeinen Menschenverstandes zu so subtiler Spekulation, niemals\n",
    "erwartet werden; hat vielmehr, was das erstere betrifft, die jedem\n",
    "Menschen bemerkliche Anlage seiner Natur, durch das Zeitliche (als\n",
    "zu den Anlagen seiner ganzen Bestimmung unzulänglich) nie zufrieden\n",
    "gestellt werden zu können, die Hoffnung eines künftigen Lebens, in\n",
    "Ansehung des zweiten die bloße klare Darstellung der Pflichten im\n",
    "Gegensatze aller Ansprüche der Neigungen das Bewußtsein der Freiheit,\n",
    "und endlich, was das dritte anlangt, die herrliche Ordnung, Schönheit\n",
    "und Fürsorge, die allerwärts in der Natur hervorblickt, allein den\n",
    "Glauben an einen weisen und großen Welturheber, die sich aufs Publikum\n",
    "verbreitende Überzeugung, sofern sie auf Vernunftgründen beruht,\n",
    "ganz allein bewirken müssen: so bleibt ja nicht allein dieser Besitz\n",
    "ungestört, sondern er gewinnt vielmehr dadurch noch an Ansehen,\n",
    "daß die Schulen nunmehr belehrt werden, sich keine höhere und\n",
    "ausgebreitetere Einsicht in einem Punkte anzumaßen, der die allgemeine\n",
    "menschliche Angelegenheit betrifft, als diejenige ist, zu der die\n",
    "große (für uns achtungswürdigste) Menge auch eben so leicht gelangen\n",
    "kann, und sich also auf die Kultur dieser allgemein faßlichen und in\n",
    "moralischer Absicht hinreichenden Beweisgründe allein einzuschränken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, in text the appearance of one character or word typically has a strong influence on the following ones. This is also reflected poorly in MLPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these insufficies of MLPs in mind lead to the development of **recurrent neural networks (RNNs)** as illustrated below in a [wonderful blogpost by Christopher Olah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, the variables $x_i$ denote sequential input such as characters or words. The symbol $A$ represents a network combining the information of the current input together with a previous output in order to obtain more refined view. The value $h_i$ can be an output of any kind, such as for instance a prediction for the most probable following character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training mechanism of RNNs is known as *backpropagation through time* and some authors feel the urge to introduce the abbreviation *BPTT*. Essentially, BPTT means considering the RNN as a feed-forward neural network and applying the standard backpropagation, as we encountered it in a [previous notebook](./sgd.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only caveat is that each weight appears once in each layer and typically the gradient signals in different layers do not agree. Hence, what is done in BPTT is to update the weights by the sum of the gradients from each of the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although RNNs do manage to capture sequential dependencies, they are myopic in the sense that incorporating information of more than two or three steps in the past remains very difficult. However, when analyzing language data it is quite common to see dependencies spanning over the entire sentence. Let me just mention that Germans love to put verbs at the end of a sentence!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason behind this limitation is known as **vanishing gradient problem**. That is, if information should be taken into account over long ranges in the sentence, then in the backpropagation mechanism the gradient signal needs to travel over many steps and therefore becomes very weak. To combat the vanishing gradient problem, in 1997 [Sepp Hochreiter and Jürgen Schmidhuber](https://www.ncbi.nlm.nih.gov/pubmed/9377276) developed the **long short-term memory (LSTM) networks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principal idea behind LSTM networks is the introduction of gates allowing gradients to travel across many layers without diminishing their strength after every step. Here is another beautiful illustration from [Christopher Olah's blogpost](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lstm.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ``Keras`` LSTMs are available as a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models,layers\n",
    "\n",
    "cell_size = 32\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(cell_size, input_shape=(None, 64)),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the concept of gates, let's take a closer look at the defining equations of the LSTM. The central architectural unit of an LSTM is a *cell* storing information stemming from possibly distant relevant parts of the input. At time step $t$ the cell state $C_t \\in \\mathbb{R}^h$ is a linear combination of the cell state $C_{t-1}$ in the previous step and an **update vector** $\\tilde{C}_{t-1}$:\n",
    "$$C_t = f_t \\cdot C_{t-1} +  i_t \\cdot \\tilde{C}_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the coefficients $f_t, i_t \\in [0,1]^h$ and the update vector $\\tilde{C}_{t} \\in [-1,1]^h$ are determined as follows. The coefficient $f_{t}$ is called **forget gate** and determines how much of the information from the previous cell should be retained. It is computed via a single-layer MLP with sigmoid-activation from the current input $x_t$ and the output $h_{t-1}$ from the previous step:\n",
    "$$f_t = \\sigma(W_{{\\mathsf{f}}}[x_t; h_{t-1}] + b_{\\mathsf{f}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the **input gate** $i_t$ determines how much of the update vector is incorporated in the $t$th step:\n",
    "$$i_t = \\sigma(W_{{\\mathsf{i}}}[x_t; h_{t-1}] + b_{\\mathsf{i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update vector $\\tilde{C}_{t}$ is also obtained as a single-layer MLP, but using a $\\tanh$-activation instead:\n",
    "$$\\tilde{C}_t = \\tanh(W_{{\\mathsf{C}}}[x_t; h_{t-1}] + b_{\\mathsf{C}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in the LSTM cell is to relate the output $h_t$ to the current cell state $C_t$:\n",
    "$$h_t = o_t \\cdot \\tanh(C_t),$$\n",
    "with the **output gate** \n",
    "$$o_t = \\sigma(W_{{\\mathsf{o}}}[x_t; h_{t-1}] + b_{\\mathsf{o}}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before letting LSTMs speak Nietzsche, we explore how useful LSTM are when working with standard numerical time series. Here, we follow [François Chollets notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.3-advanced-usage-of-recurrent-neural-networks.ipynb) on the analysis of German weather data: https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data and set the time as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn; seaborn.set()\n",
    "%matplotlib inline\n",
    "\n",
    "temp_df = pd.read_csv('./data/jena.csv')\n",
    "temp_df = temp_df.set_index('Date Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the index into datetime type.  We also reduce the time-granularity and only consider hourly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = '1H'\n",
    "\n",
    "temp_df.index = pd.to_datetime(temp_df.index)\n",
    "temp_df = temp_df.resample('1H').first().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the temperature over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f77fecf2e80>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_df.iloc[::,1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using neural networks with numeric data, it is crucial to standardize the input first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "np_scaled =  preprocessing.StandardScaler().fit_transform(temp_df)\n",
    "norm_df = pd.DataFrame(np_scaled, columns = temp_df.columns, index = temp_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As architecture, we choose an LSTM unit with cellsize 32 and optimize it with respect to mean average error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "cell_size = 32\n",
    "lr = 1e-3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(cell_size, input_shape=(None, norm_df.shape[-1])),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to feed the network with training data, we need to break it up into chunks of a manageable size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that purpose, we use a generator adapted from [François Chollets notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.3-advanced-usage-of-recurrent-neural-networks.ipynb) in order to split the data into smaller pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generator(df, start, end, lookback=5, delay=1, batch_size=128):\n",
    "    while True:\n",
    "        full_range = pd.date_range(start, end, freq='1h', closed='left')\n",
    "        \n",
    "        #choose a random mini-batch\n",
    "        batch_dates = full_range[np.random.randint(0, len(full_range), batch_size)]\n",
    "        \n",
    "        #prediction based on past data\n",
    "        samples = [df.loc[pd.date_range(date - pd.DateOffset(days=lookback), date, freq='1h', closed='right')]\n",
    "            for date in batch_dates]\n",
    "        \n",
    "        #prediction into the future\n",
    "        targets = [df.iloc[:,1].loc[date + pd.DateOffset(days=delay)]\n",
    "            for date in batch_dates]\n",
    "                            \n",
    "        yield [np.stack(st) for st in [samples, targets]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define generators for training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(norm_df, '2010', '2015')\n",
    "val_gen = generator(norm_df, '2015', '2016')\n",
    "test_gen = generator(norm_df, '2016', '2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform the actual training. Already after a small number of epochs, the validation loss stabilizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.4923 - val_loss: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09e475fcc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch=200\n",
    "epochs = 1\n",
    "validation_steps=50\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving to the language domain, we note that the above architecture only provides the most basic approach towards applying RNNs for time series data. In particular, recurrent neural networks nowadays outperform traditional time-series techniques such as *ARIMA* if one resorts to a *seq2seq* architecture. [Artur Suilin](https://github.com/Arturus/kaggle-web-traffic/blob/master/how_it_works.md) gives a beautiful explanation of these ideas together with a variety of impressive illustrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having gained experience on how LSTMs are used for numerical sequence data, we can now venture into the domain of NLP. Here, we follow in large parts [Chapter 8.1 of *Deep Learning with Python*](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.1-text-generation-with-lstm.ipynb). So, how can we get RNNs to generate text for us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is simple. We consider text as a sequence of suitably encoded characters and then train an RNN for predicting the most probable next character. We explore the strengths and weaknesses of this method by generating text from Nietzsche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the text and one-hot encode the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder( sparse = False)\n",
    "\n",
    "\n",
    "text = open('./data/nietzsche.txt').read().lower()\n",
    "text_ohe = ohe.fit_transform(le.fit_transform(list(text)).reshape(-1,1))\n",
    "nchars = ohe.n_values_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split it into shorter sequences. For each of these sequences, we also keep the following character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "step = 3\n",
    "train_size = len(range(0, len(text) - maxlen, step))\n",
    "\n",
    "\n",
    "sentences = np.zeros((train_size, maxlen, text_ohe.shape[1]))\n",
    "next_chars =  np.zeros((train_size,text_ohe.shape[1]))\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences[int(i/step),:,:] = text_ohe[i: i + maxlen,:]\n",
    "    next_chars[int(i/step),:] = text_ohe[i + maxlen,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As architecture, we choose a single-layer LSTM optimized with respect to cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "cell_size = 128\n",
    "lr = 1e-2\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(cell_size,  input_shape=(maxlen, nchars)),\n",
    "    layers.Dense(ohe.n_values_[0], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 224s 1ms/step - loss: 1.5519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50481a5908>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "\n",
    "model.fit(sentences, next_chars, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the last layer of the model is a softmax layer over the characters. In order to use the model for text-generation, we need to convert these probabilities into actual characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, we take from [François Chollets notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.1-text-generation-with-lstm.ipynb) a sampling function of characters depending on the activations in the final layer. This sampling function depends on a temperature parameter interpolating between a uniform distribution and a delta distribution on the most likely character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-5\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    logits = np.log(preds + EPS) / temperature\n",
    " \n",
    "    softmax = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    sample = np.random.multinomial(1, softmax) \n",
    "    return np.argmax(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for what must these\n",
      "clumsy attempts of feminine scientifica\n",
      "ristic and\n",
      "the become the believe the deption of the solest and real so far of believe all often anying altering to course of the securing more soul of here and surplistion as and for the species also confeduents of man enextence, and the brensting of our every delight and not stranger and whish man his sublight, it feel of a primiled to man appaint of man class\" of submly and by greatest soul whi"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "import sys \n",
    "\n",
    "seed=42\n",
    "temperature = .6\n",
    "gen_text_len = 400\n",
    "#random.seed(seed)\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "generated_text = text[start_index: start_index + maxlen]\n",
    "print(generated_text)\n",
    "\n",
    "generated_text = ohe.transform(le.transform(list(generated_text)).reshape(-1,1))\n",
    "generated_text = np.expand_dims(generated_text, 0)\n",
    "\n",
    "for i in range(gen_text_len):\n",
    "\n",
    "        preds = model.predict(generated_text, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "\n",
    "        #print char\n",
    "        sys.stdout.write(le.classes_[next_index])\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        #update text\n",
    "        new_text = np.concatenate([generated_text[:, 1:, :], \n",
    "                                   np.expand_dims(ohe.transform(next_index),0)], \n",
    "                                  axis=1)\n",
    "        generated_text = new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that RNNs can make steps into imitating Nietzsche! However, a closer look reveals that this approach produces examples that stick rather closely to the original text. Developing different generative models not suffering so strongly  from this problem is an active area of research in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After more training, the sentences would become even better. Here are examples from [Andrej Karpathy's blogpost](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) trained on Shakespeare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  VIOLA:\n",
    "Why, Salisbury must find his flesh and thought\n",
    "That which I am not aps, not a man and in fire,\n",
    "To show the reining of the raven and the wars\n",
    "To grace my hand reproach within, and not a fair are hand,\n",
    "That Caesar and my goodly father's world;\n",
    "When I was heaven of presence and our fleets,\n",
    "We spare with hours, but cut thy council I am great,\n",
    "Murdered and by thy master's ready there\n",
    "My power to give thee but so much as hell:\n",
    "Some service in the noble bondman here,\n",
    "Would show him to her wine.\n",
    "\n",
    ">KING LEAR:\n",
    "O, if you were a feeble sight, the courtesy of your law,\n",
    "Your sight and several breath, will wear the gods\n",
    "With his heads, and my hands are wonder'd at the deeds,\n",
    "So drop upon your lordship's head, and your opinion\n",
    "Shall be against your honour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the prediction based on the seq2seq model and improve the predictions above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LSTM model based on word encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
