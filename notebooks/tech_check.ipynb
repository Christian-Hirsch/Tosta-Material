{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn die folgende Zelle fehlerfrei kompiliert, so sind alle notwendigen Pakete installiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "import h5py\n",
    "import keras\n",
    "import matplotlib\n",
    "import numpy \n",
    "import pandas\n",
    "import PIL\n",
    "import scipy\n",
    "import seaborn\n",
    "import sklearn\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Zeilen soll kompiliert werden um vortrainierte Modelle und Datensaetze zu laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n",
      "[==================================================] 100.1% 13.8/13.8MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<20-newsgroups.Dataset at 0x7f48dfceca58>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.downloader.load(\"glove-twitter-25\")\n",
    "gensim.downloader.load('text8') \n",
    "gensim.downloader.load(\"20-newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-06-06 08:23:39--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
      "Løser s3.amazonaws.com (s3.amazonaws.com)... 52.216.230.173\n",
      "Tilslutter s3.amazonaws.com (s3.amazonaws.com)|52.216.230.173|:443... forbundet.\n",
      "HTTP forespørgsel sendt, afventer svar... 200 OK\n",
      "Længde: 13568290 (13M) [application/zip]\n",
      "Gemmer til: 'jena_climate_2009_2016.csv.zip.2'\n",
      "\n",
      "jena_climate_2009_2 100%[===================>]  12,94M  4,19MB/s    in 3,1s    \n",
      "\n",
      "2018-06-06 08:23:42 (4,19 MB/s) - 'jena_climate_2009_2016.csv.zip.2' gemt [13568290/13568290]\n",
      "\n",
      "--2018-06-06 08:23:42--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "Løser s3.amazonaws.com (s3.amazonaws.com)... 52.216.0.83\n",
      "Tilslutter s3.amazonaws.com (s3.amazonaws.com)|52.216.0.83|:443... forbundet.\n",
      "HTTP forespørgsel sendt, afventer svar... 200 OK\n",
      "Længde: 600901 (587K) [text/plain]\n",
      "Gemmer til: 'nietzsche.txt'\n",
      "\n",
      "nietzsche.txt       100%[===================>] 586,82K   446KB/s    in 1,3s    \n",
      "\n",
      "2018-06-06 08:23:44 (446 KB/s) - 'nietzsche.txt' gemt [600901/600901]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "!wget https://s3.amazonaws.com/text-datasets/nietzsche.txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 7s 0us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 32s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n07871810', 'meat_loaf', 0.9991093967510501),\n",
       "  ('n04344873', 'studio_couch', 0.9986441234701045),\n",
       "  ('n03590841', \"jack-o'-lantern\", 0.9966697103115089),\n",
       "  ('n03133878', 'Crock_Pot', 0.9957382570417956),\n",
       "  ('n01698640', 'American_alligator', 0.9948969539319499)]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import  VGG16\n",
    "from keras.applications.vgg19 import  VGG19\n",
    "from keras.applications.resnet50 import  ResNet50\n",
    "from keras.applications.xception import  Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import  DenseNet121\n",
    "from keras.datasets import imdb, mnist,  cifar10\n",
    "\n",
    "\n",
    "\n",
    "imdb.get_word_index()\n",
    "imdb.load_data()\n",
    "mnist.load_data()\n",
    "cifar10.load_data()\n",
    "\n",
    "\n",
    "\n",
    "vgg16 = VGG16(weights = 'imagenet', include_top = False)\n",
    "vgg19 = VGG19(weights = 'imagenet', include_top = False)\n",
    "resnet50 = ResNet50(weights = 'imagenet', include_top = False)\n",
    "xception = Xception(weights='imagenet', include_top = False)\n",
    "inception_v3 = InceptionV3(weights='imagenet', include_top = False)\n",
    "denseNet = DenseNet121(weights='imagenet', include_top = False)\n",
    "\n",
    "vgg16 = VGG16(weights = 'imagenet')\n",
    "vgg19 = VGG19(weights = 'imagenet')\n",
    "resnet50 = ResNet50(weights = 'imagenet')\n",
    "xception = Xception(weights='imagenet')\n",
    "inception_v3 = InceptionV3(weights='imagenet')\n",
    "denseNet = DenseNet121(weights='imagenet')\n",
    "\n",
    "\n",
    "keras.applications.vgg16.decode_predictions(numpy.array(numpy.random.rand(1,1000)))\n",
    "keras.applications.resnet50.decode_predictions(numpy.array(numpy.random.rand(1,1000)))\n",
    "keras.applications.xception.decode_predictions(numpy.array(numpy.random.rand(1,1000)))\n",
    "keras.applications.inception_v3.decode_predictions(numpy.array(numpy.random.rand(1,1000)))\n",
    "keras.applications.densenet.decode_predictions(numpy.array(numpy.random.rand(1,1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
